# VRAM Calculations: The Tricky Part

- Model size is straightforward to calculate
- But how much "spare" VRAM is needed for KV cache?
- KV cache grows with context length and concurrent requests
- This is the hard part to predict and optimize
- Too little = OOM errors, too much = wasted capacity
