# Centrale Repositories (ScanNet POC Fokus)

**llm-server** - https://github.com/martinmose/llm-server
Lokal vLLM server til high-performance model inference. GPU-accelereret serving med support for forskellige quantized modeller.

**llm-server-tui** - https://github.com/martinmose/llm-server-tui
Terminal user interface til monitoring og håndtering af LLM serveren.

**llm-loadtest** - https://github.com/martinmose/llm-loadtest
Inference benchmark suite til test af model performance under forskellige load conditions.

---

**Dokumentation & Læring:**
https://github.com/martinmose/zeldoc-documentation
- Omfattende dokumentation af læringsprocessen
- Meget at lære, masser af eksperimentering
- Ødelægge ting for at lære hurtigere

**Andre repositories:**
- llm-gateway: https://github.com/martinmose/llm-gateway - Smart routing mellem lokale og cloud LLM udbydere
- hetzner-iac: https://github.com/martinmose/hetzner-iac - Infrastructure as Code til Hetzner Cloud deployment
