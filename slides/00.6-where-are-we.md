# Where are we right now

- Two servers with H100 GPUs for POC testing (sponsored by ScanNet)
- Testing local LLM deployment and performance
- Evaluating feasibility of self-hosted vs. cloud solutions
- Gathering real performance metrics and cost data
